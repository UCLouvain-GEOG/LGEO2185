---
title: "LGEO2185: Introduction to Spatial Data Manipulation with R"
author: "Kristof Van Oost, Antoine Stevens & Valentin Charlier"
Date: 2026-02-11
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

# Learning Objectives

-   Understand raster/vector data-structures
-   Read/write raster/vector data
-   Data management (projections, crop, mask etc.)
-   Perform basic raster calculation
-   Extraction of values, statistics (see further Session 3 -\> spatial analysis)

::: callout-note
Before you start, you should be able to use basic *R* (R packages, drivers, bindings, functions, etc.)
:::

::: callout-warning
Download the files from this repo under `Intro To Spatial Data/data` (or clone the repo) and put this data into your *R* working directory under the folder `data/` to reproduce the code
:::

# 1. Introduction

This session introduces you to spatial data manipulation in R using the **terra** and **sf** package. In this context, *spatial data* refers to information about geographic locations (i.e., places on Earth). Although “geospatial data” is more precise, we use the shorter term “spatial” throughout this resource. This introduction is part of a broader series on spatial analysis and modeling with R. In this section, we cover the basics of spatial data manipulation. Prior familiarity with the R programming language is recommended. If you are new to R or need a refresher, consider reviewing this brief [Introduction to R](https://rspatial.org/intr).

This tutorial is based on the materials provided by the chapter `Spatial data with terra` from @sds and "terra" ([website](https://rspatial.org/spatial/index.html#))\[\^License: https://creativecommons.org/licenses/by-sa/4.0/\]

```{r, echo = FALSE, eval = FALSE}
# TODO: add other sf refs
# TODO: add infor on CRS
https://mapping-in-r-workshop.ryanpeek.org/00_mapmaking_aesthetics#Projections_and_Coordinate_Reference_Systems_(CRS)
```

## Understanding spatial data

Spatial phenomena generally fall into two categories:

1.  **Discrete Objects:**\
    These are objects with clear boundaries, such as rivers, roads, countries, towns, or research sites.

2.  **Continuous Phenomena (Spatial Fields):**\
    These are variables that can be observed across an area without natural boundaries, such as elevation, temperature, or air quality.

## Representing spatial data

-   **Vector Data:**\
    Discrete spatial objects are typically represented as vector data. This data type consists of:

    -   **Geometry:** The “shape” or spatial outline of the object.

    -   **Attributes:** Additional information associated with the object.\
        *Example:* A vector dataset might include the borders of countries (geometry) along with their names and population sizes (attributes).

-   **Raster Data:**\
    Continuous spatial phenomena are usually represented with raster data structures.

In the sections that follow, we will delve into these two data types and demonstrate how to manipulate them using R and the **terra** package.

## 1.1 Vector data

Vector data represents spatial features using geometries composed of coordinate pairs (x, y). The primary vector data types are **points**, **lines**, and **polygons**.

![Different type of vector data (@lovelace_geocomputation_2025)](images/spatial-data-type.png)

### Points

-   **Definition:**\
    A point is the simplest vector type, represented by a single coordinate pair.

-   **Attributes:**\
    Points are often associated with several variables. For example, a point might indicate where a rat was trapped, with attributes such as the capture date, the person who captured it, species details, size, sex, and habitat information.

-   **Multipoint Structures:**\
    Multiple points can be combined into a single multipoint geometry that shares one attribute record. For example, all coffee shops in a town might be represented as a single multipoint structure.

### Lines

-   **Definition:**\
    A "line" refers to one or more polylines—a connected series of line segments.

-   **Geometry:**\
    Lines are represented as ordered sets of coordinates (nodes). The order is crucial, as it dictates how the points are connected to form the line segments.

-   **Examples:**\
    A river and its tributaries can be treated as a single line or as separate lines (one for each tributary), depending on the analysis.

-   **Networks (Spatial Graphs):**\
    A network, such as a road or river network, is a specialized type of line geometry. It includes additional information about flow, connectivity, direction, and distance.

### Polygons

-   **Definition:**\
    A polygon consists of one or more closed polylines. To form a closed shape, the last coordinate pair of a polygon is the same as the first.

-   **Geometry and rules:**

    -   **Closed Shape:** The geometry of a polygon requires closure, meaning the sequence of coordinates must return to the starting point.

    -   **Holes:** Polygons can contain holes—areas entirely enclosed by the polygon that are excluded from the fill. An example is an island within a lake.

    -   **Validity:** For a polygon to be valid, it must not self-intersect (unlike lines, which can cross themselves).

-   **Multipolygon structures:**\
    Multiple polygons can be treated as a single geometry. For instance, a country like Indonesia, comprised of many islands, may be represented as a multipolygon, where each island is an individual polygon within the larger structure.

## 1.2 Raster data

Raster data is commonly used to represent spatially continuous phenomena, such as elevation. Instead of storing explicit geometries like vector data, a raster divides the world into a grid of equally sized rectangular cells (often called cells or pixels in satellite remote sensing). Each cell holds one or more values (or possibly missing values) corresponding to the variable(s) of interest.

### Key Characteristics

-   **Grid structure:**\
    The world is divided into a regular grid of cells. Each cell covers a specific, uniform area.

-   **Cell values:**

    -   Typically, a cell value represents the average or majority value for the area it covers.

    -   In some cases, the cell value is an estimate at the center of the cell, essentially treating the grid as a set of regularly spaced points with attributes.

-   **Implicit geometry:**\
    Unlike vector data, raster data does not store coordinates for each cell explicitly. Instead, the geometry is defined by:

    -   The spatial extent (boundaries) of the dataset.

    -   The number of rows and columns in the grid.\
        From these, the size of each cell (i.e., the spatial resolution) can be computed.

-   **Efficiency consideration:**\
    Representing each cell as an explicit polygon with its own coordinates would be inefficient. Not only would this increase storage requirements, but it would also significantly slow down data processing.

-   **Triangulated Irregular Networks (TINs):**\
    Although continuous surface data can also be represented using TINs, which consist of irregularly spaced triangles, this method is not covered in the current discussion.

## 1.3 Representation of spatial data

The [basic data types](http://rspatial.org/intr/2-basic-data-types.html) in *R* are numbers, characters, logical (`TRUE` or `FALSE`) and factor values.

Values of a single type can be combined in vectors and matrices, and variables of multiple types can be combined into a `data.frame`. We can represent (only very) basic spatial data with these data types. Let’s say we have the location (represented by longitude and latitude) of ten weather stations (named A to J) and their annual precipitation.

In the example below we make a very simple map. Note that a *map* is special type of plot (like a scatter plot, barplot, etc.). A map is a plot of geospatial data that also has labels and other graphical objects such as a scale bar or legend. The spatial data itself should not be referred to as a map.

```{r 1.3}
name <- LETTERS[1:10]
longitude <- c(
    -116.7, -120.4, -116.7, -113.5, -115.5,
    -120.8, -119.5, -113.7, -113.7, -110.7
)
latitude <- c(
    45.3, 42.6, 38.9, 42.1, 35.7, 38.9,
    36.2, 39, 41.6, 36.9
)
stations <- cbind(longitude, latitude)
# Simulated rainfall data
set.seed(0)
precip <- round((runif(length(latitude)) * 10)^3)
```

A map of point locations is not that different from a basic x-y scatter plot. Here I make a plot (a map in this case) that shows the location of the weather stations, and the size of the dots is proportional to the amount of precipitation. The point size is set with argument `cex`.

```{r}
psize <- 1 + precip / 500
plot(stations, cex = psize, pch = 20, col = "red", main = "Precipitation")
# add names to plot
text(stations, name, pos = 4)
# add a legend
breaks <- c(100, 250, 500, 1000)
legend.psize <- 1 + breaks / 500
legend("topright", legend = breaks, pch = 20, pt.cex = legend.psize, col = "red", bg = "gray")
```

::: callout-note
The data are represented by “longitude, latitude”, in that order, do not use “latitude, longitude” because on most maps latitude (North/South) is used for the vertical axis and longitude (East/West) for the horizontal axis. This is important to keep in mind, as it is a very common source of mistakes!
:::

We can add multiple sets of points to the plot, and even draw lines and polygons:

```{r}
lon <- c(-116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7)
lat <- c(41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6)
x <- cbind(lon, lat)
plot(stations, main = "Precipitation")
polygon(x, col = "blue", border = "light blue")
lines(stations, lwd = 3, col = "red")
points(x, cex = 2, pch = 20)
points(stations, cex = psize, pch = 20, col = "red", main = "Precipitation")
```

The above illustrates how numeric vectors representing locations can be used to draw simple maps. It also shows how points can (and typically are) represented by pairs of numbers. A line and a polygon can be represented by a number of these points. Polygons need to "closed", that is, the first point must coincide with the last point, but the `polygon` function took care of that for us.

There are cases where a simple approach like this may suffice and you may come across this in older *R* code or packages. Likewise, raster data could be represented by a matrix or higher-order array. Particularly when only dealing with point data such an approach may be practical. For example, a spatial data set representing points and attributes could be made by combining geometry and attributes in a single `data.frame`.

```{r}
wst <- data.frame(longitude, latitude, name, precip)
wst
```

However, `wst` is a data.frame and *R* does not automatically understand the special meaning of the first two columns, or to what coordinate reference system it refers (longitude/latitude, or perhaps UTM zone 17S, or ….?).

Moreover, it is non-trivial to do some basic spatial operations. For example, the blue polygon drawn on the map above might represent a state, and a next question might be which of the 10 stations fall within that polygon. And how about any other operation on spatial data, including reading from and writing data to files? To facilitate such operation a number of *R* packages have been developed that define new spatial data types that can be used for this type of specialized operations.

Recent packages in *R* that define such spatial data structures include `terra` and `sf`. These packages replace a set of older packages including `raster` and `sp`.

We will mostly use the `terra` and `sf` package in these course. You can install the latest released version of *terra* and *sf* from CRAN with `install.packages("terra")` and `install.packages("sf")`.

# 2. Vector data in `terra`

## 2.1. Introduction

The `terra` package defines a set of *classes* to represent spatial data. A class defines a particular data type. The `data.frame` is an example of a class. Any particular `data.frame` you create is an *object* (instantiation) of that class.

The main reason for defining classes is to create a standard representation of a particular data type to make it easier to write functions (known as “methods”) for them. See @wickham2019 or @chambers2008 for a detailed discussion of the use of classes in *R*.

`terra` introduces a number of classes with names that start with `Spat`. For vector data, the relevant class is `SpatVector`. These classes represent geometries as well as attributes (variables) describing the geometries.

```{r, echo = FALSE}
#TODO EXPLAIN terra awesomeness (C++ etc)
```

It is possible to create `SpatVector` objects from scratch with *R* code. This is very useful when creating a small self contained example to illustrate something, for example to ask a question about how to do a particular operation; without needing to give access to the real data you are using (which is always cumbersome). It is also frequently done when using coordinates that were obtained with a GPS. But in most other cases, you will read these from a file or database.

To get started, let’s make some `SpatVector` objects from scratch anyway, using the same data as were used in the previous chapter.

## 2.2 Points

```{r 2.2}
longitude <- c(-116.7, -120.4, -116.7, -113.5, -115.5, -120.8, -119.5, -113.7, -113.7, -110.7)
latitude <- c(45.3, 42.6, 38.9, 42.1, 35.7, 38.9, 36.2, 39, 41.6, 36.9)
lonlat <- cbind(longitude, latitude)
```

Now create a `SpatVector` object. First load the `terra` package from the library. If this command fails with `Error in library(terra) : there is no package called ‘terra’`, then you need to *install* the package first, with `install.packages("terra")`

```{r}
library(terra)
pts <- vect(lonlat)
```

Let’s check what kind of object `pts` is.

```{r}
class(pts)
```

And what is inside of it

```{r}
pts
geom(pts)
```

So we see that the object has the coordinates we supplied, but also an `extent`. This spatial extent was computed from the coordinates. There is also a coordinate reference system (“CRS”, discussed in more detail later). We did not provide the CRS when we created `pts`. That is not good, so let’s recreate the object, and now provide a CRS.

```{r}
crdref <- "+proj=longlat +datum=WGS84"
pts <- vect(lonlat, crs = crdref)
pts
crs(pts)
```

```{r, echo = FALSE}
#TODO EXPLAIN EPSG
```

We can add attributes (variables) to the `SpatVector` object. First we need a `data.frame` with the same number of rows as there are geometries.

```{r}
# Generate random precipitation values, same quantity as points
precipvalue <- runif(nrow(lonlat), min = 0, max = 100)
df <- data.frame(ID = 1:nrow(lonlat), precip = precipvalue)
```

Combine the `SpatVector` with the `data.frame`.

```{r}
ptv <- vect(lonlat, atts = df, crs = crdref)
```

To see what is inside:

```{r}
ptv
```

## 2.3 Lines and polygons

Making a `SpatVector` of points was easy. Making a `SpatVector` of lines or polygons is a bit more complex, but stil relatively straightforward.

```{r 2.3}
lon <- c(-116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7)
lat <- c(41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6)
lonlat <- cbind(id = 1, part = 1, lon, lat)
lonlat
lns <- vect(lonlat, type = "lines", crs = crdref)
lns
```

```{r}
pols <- vect(lonlat, type = "polygons", crs = crdref)
pols
```

Behind the scenes the class deals with the complexity of accommodating for the possibility of multiple polygons, each consisting of multiple sub-polygons, some of which may be “holes”. You do not need to understand how these structures are organized. The main take home message is that a `SpatVector` stores geometries (coordinates), the name of the coordinate reference system, and attributes.

We can make use `plot` to make a map.

```{r}
plot(pols, las = 1)
plot(pols, border = "blue", col = "yellow", lwd = 3, add = TRUE)
points(pts, col = "red", pch = 20, cex = 3)
```

We’ll make more fancy maps, see below !!!!

# 3. Vector data in `sf`

## 3.1. Introduction

The `sf` package provides a simple and consistent framework for working with spatial vector data in R. It is based on the concept of *simple features* as standardized by the Open Geospatial Consortium (OGC). Simple features are geometric objects that can represent points, lines, polygons, and their combinations.

The primary class in `sf` for working with vector data is `sf` (simple features). An `sf` object is essentially a data frame that includes special columns for geometric data, making it easy to manipulate attributes and geometries together. This design aligns with the tidy data principles popularized in the R ecosystem.

For a more in-depth exploration of the concepts behind `sf`, refer to the official [sf documentation](https://r-spatial.github.io/sf/)

## 3.2. Points

Let’s start by creating a set of points using the `sf` package. If you haven’t already installed `sf`, you can do so using `install.packages("sf")`.

```{r 3.2}
# Load the sf package
library(sf)

# Create a simple data frame with coordinates
data <- data.frame(ID = 1:length(lon), lon, lat)

# Convert to an sf object
points_sf <- st_as_sf(data, coords = c("lon", "lat"), crs = 4326) # crs is the projection system (here, WGS84, we will see this later)

# Inspect the structure
class(points_sf)
points_sf
```

Here, the `st_as_sf` function converts the data frame into an `sf` object, specifying the coordinate columns and the CRS (EPSG:4326 corresponds to WGS84). Let’s visualize the points:

```{r}
# Plot the points
plot(points_sf, col = "blue", pch = 20, cex = 1.5)
```

## 3.3. Lines and Polygons

Similar to points, lines and polygons can also be created using sf. Let’s first define a set of coordinates and then convert them into geometries.

```{r 3.3}
# Define coordinates for a line
line_coords <- matrix(
    c(
        -116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7,
        41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6
    ),
    ncol = 2, byrow = FALSE
)

# Create a line geometry
line_sf <- st_sfc(st_linestring(line_coords), crs = 4326)
line_sf
```

For polygons, a similar process can be followed:

```{r}
# Define coordinates for a polygon
polygon_coords <- matrix(
    c(
        -116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7, -116.8,
        41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6, 41.3
    ),
    ncol = 2, byrow = FALSE
)

# Create a polygon geometry
polygon_sf <- st_sfc(st_polygon(list(polygon_coords)), crs = 4326)
polygon_sf
```

The `sf` package simplifies the complexity of geometric structures while adhering to standards. Additionally, it allows plotting and combining geometries seamlessly with attribute data.

```{r}
# Plot the polygon with the line and points
plot(polygon_sf, col = "yellow", border = "blue", lwd = 2)
plot(line_sf, col = "red", lwd = 2, add = TRUE)
plot(points_sf, col = "green", pch = 20, cex = 1.5, add = TRUE)
```

# 4. Raster data

## 4.1 Introduction

The `terra` package has functions for creating, reading, manipulating, and writing raster data. The package provides, among other things, general raster data manipulation functions that can easily be used to develop more specific functions. For example, there are functions to read a chunk of raster values from a file or to convert cell numbers to coordinates and back. The package also implements raster algebra and many other functions for raster data manipulation.

## 4.2 SpatRaster

A `SpatRaster` represents multi-layer (multi-variable) raster data. A SpatRaster always stores a number of fundamental parameters describing its geometry. These include the number of columns and rows, the spatial extent, and the Coordinate Reference System. In addition, a `SpatRaster` can store information about the file in which the raster cell values are stored. Or, if there is no such a file, a `SpatRaster` can hold the cell values in memory.

Here I create a `SpatRaster` from scratch. But note that in most cases where real data is analyzed, these objects are created from a file.

```{r 4.2}
library(terra)
r <- rast(ncol = 10, nrow = 10, xmin = -150, xmax = -80, ymin = 20, ymax = 60)
r
```

SpatRaster `r` only has the geometry of a raster data set. That is, it knows about its location, resolution, etc., but there are no values associated with it. Let’s assign some values. In this case I assign a vector of random numbers with a length that is equal to the number of raster cells.

```{r}
values(r) <- runif(ncell(r))
r
```

You could also assign cell numbers (in this case overwriting the previous values)

```{r}
values(r) <- 1:ncell(r)
r
```

We can plot this object.

```{r}
plot(r)
# add polygon and points
lon <- c(-116.8, -114.2, -112.9, -111.9, -114.2, -115.4, -117.7)
lat <- c(41.3, 42.9, 42.4, 39.8, 37.6, 38.3, 37.6)
lonlat <- cbind(id = 1, part = 1, lon, lat)
pts <- vect(lonlat)
pols <- vect(lonlat, type = "polygons", crs = "+proj=longlat +datum=WGS84")
points(pts, col = "red", pch = 20, cex = 3)
lines(pols, col = "blue", lwd = 2)
```

You can create a multi-layer object using the `c` method.

```{r}
r2 <- r * r
r3 <- sqrt(r)
s <- c(r, r2, r3)
s
```

## 4.3 SpatRasterDataset

A `SpatRasterDataset` is a collection of SpatRaster objects, often representing different layers or time series data. This is particularly useful when working with multi-band raster files or datasets stored in multiple files.

```{r, echo = FALSE}
# Create a SpatRasterDataset from the files
rr <- sds(s,s,s)
names(rr) <- c("Precip","Temp","Humid")

# Check the number of layers
nlyr(rr)
```

# 5. Reading and writing spatial data

## 5.1 Introduction

Reading and writing spatial data is complicated by the fact that there are many different file formats. However, there are a few formats that are most common that we discuss here.

## 5.2 Vector files

The `shapefile` is the most commonly used file format for vector data (if you are not familiar with this file format, an important thing to understand is that a [shapefile](https://en.wikipedia.org/wiki/Shapefile) is really a set of at least three (ideally four) files, with all the same name, but different extension. For shapefile `x` you *must* have, in the same directory, these three files: `x.shp`, `x.shx`, `x.dbf`, and ideally also `x.prj`.

It is easy to read and write such files. Here we use a shapefile that you can download from the Teams channel under the `/data` folder (you should put this data files into your current working directory).

### Reading

```{r 5.2}
filename <- "data/France.shp"
```

Now we have the filename we can use the `vect` function to read the file.

```{r}
s <- vect(filename)
s

# using sf is as easy
s_sf <- st_read(filename)
s_sf
```

The `vect` function returns `SpatVector` objects. It is important to recognise the difference between this type of *R* object (`SpatVector`), and the file (“shapefile”) that was used to create it. Thus, you should never say “I have a shapefile in R”, say “I have a SpatVector of polygons in R”, (and in some cases you can add “created from a shapefile”). The shapefile is one of many file formats for vector data.

### Writing

You can write new files using the `writeVector` method. You need to add argument `overwrite=TRUE` if you want to overwrite an existing file.

```{r}
# use geopackage rather than shapefile. you'll be able to keep column names and write only one file to disk :-)
outfile <- "data/shp_test.gpkg"
writeVector(s, outfile, overwrite = TRUE)
```

To remove the file again you can use `file.remove` or `unlink` (be careful!)

```{r}
ff <- list.files("data", patt = "^shp_test", full.names = TRUE) # needed if you had many files (eg. shapefile)
file.remove(ff)
```

## 5.3 Raster files

The actual data used in geo processing projects often comes as geo-data, stored on files such as GeoTiff or other commonly used file formats. Reading data directly from these files into the *R* working environment (as SpatRaster objects ), is made possible thanks to the terra package.

### Reading

Use the raster files "chm_lidar.tif" and "Lubumbashi_Sentinel2.tif" which you can download in the data folder for this session: Note that "`chm_lidar.tif`" gives you a tree canopy height model (in m) for a forest in the DR Congo. The Sentinel2 image is a multi-band false color composite (RGB).

```{r 5.3}
lidar <- rast("data/chm_lidar.tif")
plot(lidar)
# see the col options in ?plot
plot(lidar, col = colorRampPalette(c("red", "white", "blue"))(255))
```

Load the following sentinel2 image. Note that it has 3 layers and that you can access the separate bands using the `$`. You can also subset a single layer (see below)

```{r}
Lushi <- rast("data/Lubumbashi_Sentinel2b.tif")
Lushi
plot(Lushi)
plot(Lushi$Lubumbashi_Sentinel2b_1)
Lushi[[2]]
```

### Writing

Use `writeRaster` to write raster data. You must provide a `SpatRaster` and a filename. The file format will be guessed from the filename extension. If that does not work you can provide an argument like `format=GTiff`. Note the argument `overwrite=TRUE` and see `?writeRaster` for more arguments, such as datatype= to set the a specific datatype (e.g., integer).

```{r}
writeRaster(lidar, "data/CHM_lidar_copy.tif", overwrite = TRUE)
```

# 6. Coordinate Reference Systems

## 6.1 Introduction

A very important aspect of spatial data is the coordinate reference system (CRS) that is used. For example, a location of (140, 12) is not meaningful if you do know where the origin (0,0) is and if the x-coordinate is 140 meters, feet, nautical miles, kilometers, or perhaps degrees away from the x-origin.

## 6.2 Coordinate Reference Systems (CRS)

### 6.2.1 Projections

A major question in spatial analysis and cartography is how to transform this three dimensional angular system to a two dimensional planar (sometimes called “Cartesian”) system. A planar system is easier to use for certain calculations and required to make maps (unless you have a 3-d printer). The different types of planar coordinate reference systems are referred to as “projections”. Examples are “Mercator”, “UTM”, “Robinson”, “Lambert”, “Sinusoidal” and “Albers”.

There is not one best projection. Some projections can be used for a map of the whole world; other projections are appropriate for small areas only. One of the most important characteristics of a map projection is whether it is “equal area” (the scale of the map is constant) or “conformal” (the shapes of the geographic features are as they are seen on a globe). No two dimensional map projection can be both conformal and equal-area (but they can be approximately both for smaller areas, e.g. UTM, or Lambert Equal Area for a larger area), and some are neither.

### 6.2.2 Notation

A planar CRS is defined by a projection, datum, and a set of parameters. The parameters determine things like where the center of the map is. The number of parameters depends on the projection. It is therefore not trivial to document a projection used, and several systems exist. In *R* we used to depend on the [PROJ.4](ftp://ftp.remotesensing.org/proj/OF90-284.pdf) notation. PROJ.4 is the name of a software library that is commonly used for CRS transformation.

Here is a list of [commonly used projections](http://www.remotesensing.org/geotiff/proj_list/) and their parameters in PROJ4 notation. You can find many more of these on [spatialreference.org](http://spatialreference.org/ref/epsg/4326/)

The `PROJ.4` notation is no longer fully supported in the newer versions of the library. It still works for CRSs with the WGS84 datum. For other cases you have to use a EPSG code (if available) or a Well-Known-Text notation.

Most commonly used CRSs have been assigned a “EPSG code” (EPSG stands for European Petroleum Survey Group). This is a unique ID that can be a simple way to identify a CRS. For example `EPSG:27561` is equivalent to `+proj=lcc +lat_1=49.5 +lat_0=49.5 +lon_0=0 +k_0=0.999877341 +x_0=6 +y_0=2 +a=6378249.2 +b=6356515` `+towgs84=-168,-60,320,0,0,0,0 +pm=paris +units=m +no_defs`.

Now let’s look at an example with a spatial data set in *R*.

```{r 6.2}
p <- vect("data/France.shp")
p
```

We can inspect the coordinate reference system like this.

```{r}
crs(p)
```

## 6.3 Assigning a CRS

Sometimes we have data without a CRS. This can be because the file used was incomplete, or perhaps because we created the data ourselves with *R* code. In that case we can assign the CRS **if we know what it should be**. Here I first remove the CRS of `pp` and then I set it again.

```{r 6.3}
pp <- p
crs(pp) <- ""
crs(pp)
crs(pp) <- "+proj=longlat +datum=WGS84"
crs(pp)
```

::: callout-note
You should **not** use this approach to change the CRS of a data set from what it **is** to what you **want it to be**. Assigning a CRS is like labeling something. You need to provide the label that corresponds to the item. Not to what you would like it to be. For example if you label a bicycle, you can write “bicycle”. Perhaps you would prefer a car, and you can label your bicycle as “car” but that would not do you any good. It is still a bicycle. You can try to transform your bicycle into a car. That would not be easy. Transforming spatial data is easier.
:::

## 6.4 Transforming vector data

We can transform these data to a new data set with another CRS using the `project` method.

Here we use the Belgian Lambert 72 projection. First we need to find the correct notation. [spatialreference.org](http://spatialreference.org/ref/epsg/31370/)

```{r 6.4}
p <- vect("data/France.shp")
newcrs <- "EPSG:31370"
France_Lambert <- terra::project(p, newcrs)
plot(France_Lambert)
p
France_Lambert
```

After the transformation, the units of the geometry are no longer in degrees, but in meters away from (longitude=0, latitude=0). The spatial extent of the data is also in these units.

## 6.4 Transforming raster data

Vector data can be transformed from lon/lat coordinates to planar and back without loss of precision. This is not the case with raster data. A raster consists of rectangular cells of the same size (in terms of the units of the CRS; their actual size may vary). It is not possible to transform cell by cell. For each new cell, values need to be estimated based on the values in the overlapping old cells. If the values are categorical data, the “nearest neighbor” method is commonly used. Otherwise some sort of interpolation is employed (e.g. “bilinear”).

Because projection of rasters affects the cell values, in most cases you will want to avoid projecting raster data and rather project vector data. But here is how you can project raster data.

```{r}
Lushi <- rast("data/Lubumbashi_Sentinel2b.tif")
newcrs <- "EPSG:31370"
Lushi_Lambert <- terra::project(Lushi, newcrs)
plot(Lushi_Lambert)
```

But that is not a good method. As you should want to assure that you project to exactly the raster parameters you need (so that it lines up with other raster data you are using).

To have this kind of control, provide an existing SpatRaster with the geometry (ie extent and resolution) you desire. Check out `?project` for all the options. That is generally the best way to project raster. By providing an existing SpatRaster, such that your newly projected data perfectly aligns with it.

```{r}
pr3 <- terra::project(Lushi, Lushi_Lambert)
```

For raster based analysis it is often important to use equal area projections, particularly when large areas are analyzed. This will assure that the grid cells are all of same size, and therefore comparable to each other, especially when count data are used.

# 7. Maps and online resources

## 7.1 Vector data from the geodata package

`geodata` is an *R* package for downloading geographic data. This package facilitates access to climate, elevation, soil, crop, species occurrence, and administrative boundary data, and is a successor of the `getData()` function from the `raster` package. You can find a very detailed description of the data that is available [here](https://github.com/rspatial/geodata?tab=readme-ov-file#data). Explore this!

You can install the released version of `geodata` in your *R* environment from [CRAN](https://cran.r-project.org/)

```{r 7.1, eval=FALSE}
install.packages("geodata")
```

Type `?geodata` to see the help for this function. We can now easily access data from different online sources such as the Global Administrative Area Data base. Before we start, let's have a look at the settings for the `geodata` package. When you request data, you can download it locally on your computer. It makes sense to assign a fixed folder so you only have to download the data once. You can do these using the following code. With the `geodata_path()`function you can request the path. Cool!

```{r}
library(geodata)
options(geodata_default_path = "data")
geodata_path()
```

Now download France from the GADM database. Have a look at the options for this function by typing `?gadm`

```{r gadm}
adm <- gadm(country = "FRA", level = 2, download = TRUE)
plot(adm)
```

Note that you can use datasets which are available locally as they are stored as `*.rds`files. The file is saved as and *.RDS file: this file stores the* R\* data object in its own binary format. (note that you have to point to your `geodata_path()`, subfolder that represents the dataset (in this case GADM) and the filename.

```{r}
filename <- file.path(geodata_path(), "/gadm/gadm41_FRA_2_pk.rds")
France_SpatV <- vect(filename)
```

Explore the object using the following functions:

```{r, eval = FALSE}
class(France_SpatV)
names(France_SpatV)
summary(France_SpatV)
head(France_SpatV)
France_SpatV$NAME_1
France_SpatV
```

We can now explore the different component of the data object using the "\$" characters

```{r}
head(France_SpatV$GID_2)
France_SpatV$NAME_1
```

We can also investigate the characteristics of spatial vector using the following functions

```{r}
crs(France_SpatV, proj = T)
ext(France_SpatV)
```

and subset...

```{r}
fraL2_s <- France_SpatV[which(France_SpatV$GID_1 == "FRA.1_1"), ] # subset the spatial object
plot(fraL2_s)
plot(France_SpatV)
plot(fraL2_s, col = "red", add = T)
```

other ways to subset

```{r}
fraL2_s2 <- subset(France_SpatV, France_SpatV$GID_1 == "FRA.1_1") # subset the spatial object

df <- as.data.frame(France_SpatV[which(France_SpatV$GID_1 == "FRA.1_1"), ]) # subset only the data.frame of the spatial object
```

## 7.2 Leaflet

Leaflet is one of the most popular open-source JavaScript libraries for interactive maps. It is used by websites ranging from The New York Times and The Washington Post as well as GIS specialists like OpenStreetMap, Mapbox and CartoDB. There is an *R* package that makes it easy to integrate and control leaflet maps in R. Here we show some basic examples. More information can be found [here](https://rstudio.github.io/leaflet/).

First, you need to install the leaflet package and direct *R* to use the library:

```{r 7.2, eval=FALSE}
install.packages("leaflet")
```

```{r}
library(leaflet)
m <- leaflet()
m <- addTiles(m)
m <- addMarkers(m, lng = 4.62080, lat = 50.66607, popup = "UCL Geo, I'm here with you right now ;)")
```

`m` is a leaflet htmlwidget (use `class(m)` to verify this). You can now visualize this with:

```{r}
m
```

You can now easily overlay vector files. Note that we can use the *R* 'pipes' (`%\>%`) to simplify this code: the shortcut for the pipe operator is ctrl+shift+M.Be carefull here, the function does not know how to access to the spatial vector. Tips: you can transform the spatial vector in a *sf* (simple features) with `st_as_sf` function from the `sf` package.

```{r}
m2 <- leaflet() %>%
    addTiles() %>%
    addPolygons(data = France_SpatV)
m2
```

```{r}
cities <- read.csv("data/cities_FRA.csv")
cities <- vect(cities, geom = c("long", "lat"))
crs(cities) <- "+proj=longlat +datum=WGS84"
```

Add Polygons subset and cities

```{r}
m2 <- leaflet() %>%
    addTiles() %>%
    addPolygons(data = France_SpatV) %>%
    addPolygons(data = fraL2_s, fillOpacity = 1, color = "red") %>%
    addCircleMarkers(data = cities, popup = ~ as.character(city), label = ~ as.character(city), radius = ~ (exp(pop) / 100), color = "green", fillOpacity = 1)
m2
```

You can read more about this [here](http://blog.revolutionanalytics.com/2014/07/magrittr-simplifying-r-code-with-pipes.html)

Note that this map is shown in the Viewer and can be saved as an html page using the Export function.

### 7.2.1 Third-Party Tiles

Alternatively, many popular free third-party basemaps can be added using the addProviderTiles() function, which is implemented using the leaflet-providers plugin. See here for the complete set. Note that some tile set providers require you to register; see the project page for more information.

```{r}
addProviderTiles(map = m, provider = "OpenTopoMap")
```

### 7.2.2 WMS Tiles

You can use addWMSTiles() to add WMS (Web Map Service) tiles.

```{r}
m <- leaflet() %>%
    addTiles("http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}",
        attribution = "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid,IGN, IGP, UPR-EGP, and the GIS User Community"
    )
m
```

There we go. Note that this code pulls in a tile set, and allows you to set attributions for the tiles in the bottom right. Always be sure to include attribution for whoever made the map tiles!

This code also assigns the leaflet map to “m”. We can now use the pipe operator to put different layers on this basic map. This is useful if you want to manage several different map backgrounds, or a single default map that you want to show with different data layers.

Though the map has a zoom button built in, you can also set the initial starting map center and zoom level explicitly.

```{r}
m %>%
    setView(4.62080, 50.66607, zoom = 16)
```

You can also built your own tiles from a raster map. Here is an example of a tillage erosion map from Kristof's website. It is possible to create your own tiles (eg Tilemill application)…

```{r}
leaflet() %>%
    setView(4.62080, 50.66607, zoom = 6) %>%
    addTiles(
        urlTemplate = "http://www.climate.be/users/vanoost/Maps/TilMapV500/{z}/{x}/{y}.png",
        attribution = "Data source: KVO", options = tileOptions(minZoom = 3, maxZoom = 13, tms = TRUE)
    ) %>%
    addPolygons(data = France_SpatV, col = "black", weight = 2, smoothFactor = 0.3)
```

Note the url to Kristof's website and the formatting options at the end the command.

### 7.2.3 Lets plot some data

Get Earthquake data from the USGS server (check out the website for more information):

```{r}
m3 <- leaflet()
EQ <- read.csv("http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv", header = TRUE)
m3 %>%
    addCircles(data = EQ, color = "red")
```

You can now easily adjust this:

```{r}
m %>%
    addTiles() %>%
    addCircleMarkers(
        data = EQ,
        radius = ~ exp(mag) / 100, color = "red"
    )
```

or a bit more sophisticated

```{r}
m %>%
    addTiles() %>%
    addMarkers(data = subset(EQ, mag > 6), ~longitude, ~latitude, popup = ~ as.character(mag))
```

Note the use of the `subset()` function to select Earthquakes with a magnitude larger than 6. Easy!

## 7.3 rasterVIS

The [rasterVis](https://oscarperpinan.github.io/rastervis/#intro) package complements the terra package. Install this package: `install.packages("rasterVis")` and call the library

```{r 7.3}
tmin1 <- rast("data/tmin1crop.tif")
library(geodata)
tmin <- geodata::worldclim_global(var = "tmin", res = 10)
library(rasterVis)
```

Different plotting functions:

```{r}
histogram(tmin1)
```

```{r}
persp(tmin1)
```

```{r}
plot(tmin1)
contourplot(tmin1, add = TRUE) # you can add a contourplot by setting the add option to TRUE
```

```{r}
levelplot(tmin1)
```

```{r, eval = TRUE, cache = TRUE}
#| cache: true
bwplot(tmin)
pairs(tmin)
```

```{r}
densityplot(tmin1)
```

# 8. Data manipulation

## 8.1 Vector (with `terra`)

This section illustrates some ways in which we can manipulate vector data. We start with an example `SpatVector` that we read from a shapefile.

```{r 8.1}
library(terra)
p <- vect("data/France.shp")
p
```

We can plot these data in many ways. For example:

```{r}
plot(p, "NAME_2")
```

### 8.1.1 Geometry and attributes

To extract the attributes (data.frame) from a SpatVector, use:

```{r}
d <- as.data.frame(p)
head(d)
```

### 8.1.2 Variables

You can extract a variable as you would do with a `data.frame`.

```{r}
p$NAME_2
```

To subset a SpatVector to one or more variables you can use the notation below. Note how this is different from the above example. Above a vector of values is returned. With the approach below you get a new SpatVector with only one variable.

```{r}
p[, "NAME_2"]
```

### 8.1.3 Merge

You can assign an attributes table (data.frame) to a SpatVector with `values<-`. To add attributes to a SpatVector that already has attributes use `merge` (or `cbind` if you know the order of the records is the same).

```{r}
dfr <- data.frame(District = p$NAME_1, Canton = p$NAME_2, Value = round(runif(length(p), 100, 1000)))
dfr <- dfr[order(dfr$Canton), ]
pm <- merge(p, dfr, by.x = c("NAME_1", "NAME_2"), by.y = c("District", "Canton"))
pm
```

Selecting rows (records)

```{r}
i <- which(p$NAME_2 == "Ain")
g <- p[i, ]
g
```

## 8.2 Vector (with `sf`)

As explained earlier, `sf` can integrate seamlessly with the tidyverse by treating spatial objects as tibbles with an additional geometry column. This makes operations intuitive and consistent with other `tidyverse` functions (e.g., easily plot spatial data with `ggplot2`).

The `st_read()` function loads the shapefile and returns it as an `sf` object. Let’s inspect the object:

```{r 8.2}
# Load required libraries
library(sf)
library(dplyr)
library(ggplot2)

# Read the shapefile
france_sf <- st_read("data/France.shp")
# Inspect the `sf` object
glimpse(france_sf)
```

Notice how the geometry column stores spatial data while other columns contain attribute information.

### 8.2.1 Basic Operations

Since `sf` integrates with the `tidyverse`, we can use familiar functions like `filter()`, `mutate()`, and `select()`.

Let’s join some population data and filter regions ....

```{r}
# add population density
population_density <- data.frame(
    NAME_1 = c(
        "Île-de-France", "Hauts-de-France", "Provence-Alpes-Côte d'Azur", "Bretagne",
        "Pays de la Loire", "Auvergne-Rhône-Alpes", "Normandie", "Grand Est",
        "Occitanie", "Nouvelle-Aquitaine", "Centre-Val de Loire", "Bourgogne-Franche-Comté", "Corse"
    ),
    population_density = c(1027, 189, 161, 120, 119, 113, 109, 97, 87, 72, 64, 59, 40),
    geographic_location = c(
        "North", "North", "South", "West",
        "West", "East", "West", "East",
        "South", "West", "West", "East", "South"
    )
)

france_sf <- france_sf %>%
    left_join(population_density)

# Filter
france_sf_filtered <- france_sf %>%
    filter(population_density <= 100)

# Preview the result
head(france_sf_filtered)
```

Plotting spatial data with `ggplot2` is simple too. The `geometry` column is automatically recognized.

```{r}
# Plot the regions with population density
ggplot(france_sf) +
    geom_sf(aes(fill = population_density)) +
    scale_fill_viridis_c() +
    theme_minimal() +
    labs(
        title = "Population Density in France",
        fill = "Density (people per unit area)"
    )
```

### 8.2.2 Spatial Operations

`sf` allows spatial operations like intersections, unions, and transformations. See below for an exhaustive list of functions

[![Source: (\<https://rstudio.github.io/cheatsheets/sf.pdf\>)\[https://rstudio.github.io/cheatsheets/sf.pdf\]](images/sf_cheat1.png){fig-align="center"}](https://rstudio.github.io/cheatsheets/sf.pdf)

[![Source: (://rstudio.github.io/cheatsheets/sf.pdf\>)\[https://rstudio.github.io/cheatsheets/sf.pdf\]](images/sf_cheat2.png){fig-align="center"}](https://rstudio.github.io/cheatsheets/sf.pdf)

### 8.2.3 Be Careful with summarizing functions on `sf` objects...

When working with `sf` objects, summarizing functions can unintentionally create unions of geometries. This is because the `geometry` column, which stores spatial data, is treated as part of the dataset and will be summarized too. While this behavior can be desirable for some use cases, it may not always be what we want.

#### Example: Summarizing without dropping geometry

Let’s calculate the average population density by region type (without weighting by ara). Here’s what happens if we summarize without handling the geometry column explicitly:

```{r}
library(tictoc)
# Summarizing without dropping geometry
tictoc::tic() # to check computation time
region_summary <- france_sf %>%
    group_by(geographic_location) %>%
    summarize(
        population_density = mean(population_density, na.rm = TRUE)
    )
tictoc::toc()
# Inspect the result
print(region_summary)
```

Note how it returns just four rows corresponing to the four`geographic_locations`. In this case, the `geometry` column is aggregated by creating unions of geometries for each group, which can be computationally intensive and not always necessary. Note that we could use other operators than `st_union()` like `st_combine()`: it combines geometries into a single geometry collection without dissolving boundaries or ensuring topological validity. This is faster and ideal for non-spatial aggregations where the geometry is still needed. We would do:

```{r}
tictoc::tic()
# Summarize with st_combine
region_summary_combine <- france_sf %>%
    group_by(geographic_location) %>%
    summarize(
        population_density = mean(population_density, na.rm = TRUE),
        geometry = st_combine(geometry) # Use st_combine instead of default st_union
    )
tictoc::toc()
# Much faster!
# Inspect the result
print(region_summary_combine)
```

#### Avoiding geometry unions with `st_drop_geometry`

If we want to summarize the data without creating geometry unions, we need to drop the geometry column before applying the summarizing functions. This can be done using `st_drop_geometry()`. This approach is computationally efficient and avoids unintended spatial operations.

```{r}
# Drop geometry before summarizing
region_summary_no_geom <- france_sf %>%
    st_drop_geometry() %>%
    group_by(geographic_location) %>%
    summarize(
        population_density = mean(population_density, na.rm = TRUE)
    )

# Inspect the result
print(region_summary_no_geom)
```

## 8.3 Raster

We use the `geodata` function to download some climate date (type `?geodata` for help and try to understand the structure and content of the data they provide)

```{r 8.3}
tmin <- geodata::worldclim_global(var = "tmin", res = 10)
```

This is a Raster with 12 layers, representing a value for each month of the year. Check out how the download created a folder in your current geodata path Plot the raster using `plot(tmin)` You can load a single layer into a raster object:

```{r}
tmin1 <- rast(file.path(geodata_path(), "climate/wc2.1_10m/wc2.1_10m_tmin_01.tif")) # Tmin for January
plot(tmin1 / 10) # why dividing by 10? ?worldclim
```

Easy! The raster function reads many different formats, including Arc ASCII grids or netcdf files (see terra help).

### 8.3.1 Cropping rasters

There are many ways to crop rasters, you can provide coordinates for the limits of the region of interest (see example), or you can provide another SpatVector or SpatRaster as argument.

```{r 8.3.1}
newext <- ext(-10, 5, 30, 40)
tmin1.c <- crop(tmin1, newext)
plot(tmin1.c)
# or
tmin1.c.copy <- crop(tmin1, tmin1.c)
```

### 8.3.2 Algebra

Many generic functions that allow for simple and elegant raster algebra have been implemented for `Raster` objects, including the normal algebraic operators such as `+`, `-`, `*`, `/`, logical operators such as `>`, `>=`, `<`, `==`, `!` and functions like `abs`, `round`, `ceiling`, `floor`, `trunc`, `sqrt`, `log`, `log10`, `exp`, `cos`, `sin`, `atan`, `tan`, `max`, `min`, `range`, `prod`, `sum`, `any`, `all`. In these functions you can mix `raster` objects with numbers, as long as the first argument is a `raster` object. Plot r and s when you apply the algebra!

```{r 8.3.2}
r <- rast("data/chm_lidar.tif")
s <- r + 10
s <- sqrt(s)
s <- s * r + 5
values(r) <- runif(ncell(r)) # check ?runif, just random numbers
r <- round(r)
r <- r == 0 # becomes True of False
s[r] <- -0.5
s[!r] <- 5
s[s == 5] <- 15
```

Summary functions (`min`, `max`, `mean`, `prod`, `sum`, `median`, `cv`, `range`, `any`, `all`) always return a `SpatRaster` object. Perhaps this is not obvious when using functions like `min`, `sum` or `mean`.

```{r}
a <- mean(r, s, 10)
b <- sum(r, s)
st <- c(r, s, a, b)
sst <- sum(st)
sst
```

Use `global` if you want a single number summarizing the cell values of each layer.

```{r}
global(st, "sum")
```

### 8.3.3 ‘High-level’ functions

Several ‘high level’ functions have been implemented for `SpatRaster` objects. ‘High level’ functions refer to functions that you would normally find in a computer program that supports the analysis of raster data. Here we briefly discuss some of these functions. All these functions work for raster datasets that cannot be loaded into memory. See the help files for more detailed descriptions of each function.

The high-level functions have some arguments in common. The first argument is typically a `SpatRaster` ‘x’ or ‘object’. It is followed by one or more arguments specific to the function (either additional `SpatRaster` objects or other arguments), followed by `filename` and `...` arguments.

The default filename is an empty character `""`. If you do not specify a filename, the default action for the function is to return a `raster` object that only exists in memory. However, if the function deems that the `raster` object to be created would be too large to hold in memory, it is written to a temporary file instead.

The `...` argument allows for setting additional arguments that are relevant when writing values to a file: the file format, datatype (e.g. integer or real values), and a to indicate whether existing files should be overwritten.

### 8.3.4 Modifying a SpatRaster object

There are several functions that deal with modifying the spatial extent of `SpatRaster` objects. The `crop` function lets you take a geographic subset of a larger `raster` object. You can crop a `SpatRaster` by providing an extent object or another spatial object from which an extent can be extracted (objects from classes deriving from `Raster` and from `Spatial` in the `sp` package). An easy way to get an extent object is to plot a `SpatRaster` and then use `drawExtent` to visually determine the new extent (bounding box) to provide to the crop function.

`trim` crops a `SpatRaster` by removing the outer rows and columns that only contain `NA` values. In contrast, `extend` adds new rows and/or columns with `NA` values. The purpose of this could be to create a new `SpatRaster` with the same Extent of another, larger, `SpatRaster` such that they can be used together in other functions.

The `merge` function lets you merge 2 or more SpatRaster objects into a single new object. The input objects must have the same resolution and origin (such that their cells neatly fit into a single larger raster). If this is not the case you can first adjust one of the SpatRaster objects with `aggregate`/`disagg` or `resample`.

`aggregate` and `disagg` allow for changing the resolution (cell size) of a `SpatRaster` object. In the case of `aggregate`, you need to specify a function determining what to do with the grouped cell values `mean`. It is possible to specify different (dis)aggregation factors in the x and y direction. `aggregate` and `disagg` are the best functions when adjusting cells size only, with an integer step (e.g. each side 2 times smaller or larger), but in some cases that is not possible.

For example, you may need nearly the same cell size, while shifting the cell centers. In those cases, the `resample` function can be used. It can do either nearest neighbor assignments (for categorical data) or bilinear interpolation (for numerical data). Simple linear shifts of a Raster object can be accomplished with the `shift` function or with the `extent` function.

With the `warp` function you can transform values of `SpatRaster` object to a new object with a different coordinate reference system.

Here are some simple examples.

Aggregate and disaggregate.

```{r 8.3.4}
r <- rast()
values(r) <- 1:ncell(r)
ra <- aggregate(r, 20)
rd <- disagg(ra, 20)
```

Crop and merge example.

```{r}
r1 <- crop(r, ext(-50, 0, 0, 30))
r2 <- crop(r, ext(-10, 50, -20, 10))
m <- merge(r1, r2, filename = "data/test.tif", overwrite = TRUE)
plot(m)
```

`flip` lets you flip the data (reverse order) in horizontal or vertical direction – typically to correct for a ‘communication problem’ between different *R* packages or a misinterpreted file. `rotate` lets you rotate longitude/latitude rasters that have longitudes from 0 to 360 degrees (often used by climatologists) to the standard -180 to 180 degrees system. With `t` you can rotate a `SpatRaster` object 90 degrees.

### 8.3.5 Overlay

`app` (short for “apply”) allows you to do a computation for a single `SpatRaster` object by providing a function, e.g. `sum`.

The `lapp` (layer-apply) function can be used as an alternative to the raster algebra discussed above.

### 8.3.6 Classify

You can use `classify` to replace ranges of values with single values, or to substitute (replace) single values with other values.

```{r 8.2.6}
r <- rast(ncol = 3, nrow = 2)
values(r) <- 1:ncell(r)
values(r)
```

Set all values above 4 to `NA`

```{r}
s <- app(r, fun = function(x) {
    x[x < 4] <- NA
    return(x)
})
as.matrix(s)
```

Divide the first raster with two times the square root of the second raster and add five.

```{r}
rs <- c(r, s)
w <- lapp(rs, fun = function(x, y) {
    x / (2 * sqrt(y)) + 5
})
as.matrix(w)
```

Remove from `r` all values that are `NA` in `w`.

```{r}
u <- mask(r, w)
as.matrix(u)
```

Replace `NA` values in `w` with values of `r`.

```{r}
cvr <- cover(w, r)
as.matrix(w)
```

Identify the cell values in `u` that are the same as in `s`.

```{r}
v <- u == s
as.matrix(v)
```

Change value between 0 and 2 to 1, etc.

```{r}
x <- classify(w, rbind(c(0, 2, 1), c(2, 5, 2), c(4, 10, 3)))
as.matrix(x)
```

Substitute 2 with 40 and 3 with 50.

```{r}
y <- classify(x, cbind(id = c(2, 3), v = c(40, 50)))
as.matrix(y)
```

### 8.3.7 Vector to raster conversion

The terra package supports point, line, and polygon to raster conversion with the `rasterize` function. For vector type data (points, lines, polygons), `SpatVector` objects are used; but points can also be represented by a two-column matrix (x and y).

Point to raster conversion is often done with the purpose to analyze the point data. For example to count the number of distinct species (represented by point observations) that occur in each raster cell. `rasterize` takes a `SpatRaster` object to set the spatial extent and resolution, and a function to determine how to summarize the points (or an attribute of each point) by cell.

Polygon to raster conversion is typically done to create a `SpatRaster` that can act as a mask, i.e. to set to `NA` a set of cells of a `SpatRaster` object, or to summarize values on a raster by zone. For example a country polygon is transferred to a raster that is then used to set all the cells outside that country to `NA`; whereas polygons representing administrative regions such as states can be transferred to a raster to summarize raster values by region.

It is also possible to convert the values of a `SpatRaster` to points or polygons, using `as.points` and `as.polygons`. Both functions only return values for cells that are not `NA`.

### 8.3.8 Summarizing functions

When used with a `SpatRaster` object as first argument, normal summary statistics functions such as `min`, `max` and `mean` return a `SpatRaster`. You can use `global` if, instead, you want to obtain a summary for all cells of a single `SpatRaster` object. You can use `freq` to make a frequency table, or to count the number of cells with a specified value. Use `zonal` to summarize a `SpatRaster` object using zones (areas with the same integer number) defined in a `SpatRaster` and `crosstab` to cross-tabulate two `SpatRaster` objects.

```{r 8.3.8}
r <- rast(ncol = 36, nrow = 18)
values(r) <- runif(ncell(r))
global(r, mean)
```

Zonal stats, below `r` has the cells we want to summarize, `s` defines the zones, and the last argument is the function to summarize the values of `r` for each zone in `s`.

```{r}
s <- r
values(s) <- round(runif(ncell(r)) * 5)
zonal(r, s, "mean")
```

Count cells

```{r}
freq(s)
freq(s, value = 3)
```

Cross-tabulate

```{r}
ctb <- crosstab(c(r * 3, s))
head(ctb)
```

### 8.3.9 Coercion to other classes

You can convert `SpatRaster` objects to `Raster*` objects defined in the `raster` package.

```{r}
r <- rast(ncol = 36, nrow = 18)
values(r) <- runif(ncell(r))
library(raster)
## Loading required package: sp
x <- raster(r)
```

::: assignment
# Assignment

Write an *R* script that plots the altitude versus the precipitation for the month August and January. You can do this by combining the functions described above.

Use the file `SRTM_EastDRC.tif` for altitude and the geodata package to download the worldclim precipitation. The SRTM_East_DRC.tif defines the study area (The eastern part of the DRC). You can create a simple scatter plot of two raster as follows: `plot(srtm,prec8_c_rs)` but consider using a subsample of the two rasters using the `sample`function from the `terra` [package](https://rdrr.io/cran/terra/man/sample.html). The `extract` function will allow you to create your database. You can use the `ggplot2`package to create a scatter plot where you group the data per month (see below).

Finally, create an interactive map where you plot the precipitation data for three cities in the region, as given by the SpatVector `ptv`:

```{r, eval=FALSE}
longitude <- c(29.223746483619934, 28.83098527307172, 29.36107555829668)
latitude <- c(-1.6497881077672947, -2.5198698843888763, -3.3619524364282487)
crdref <- "+proj=longlat +datum=WGS84"
f <- as.data.frame(c("Goma", "Bukavu", "Bujumbura"))
ptv <- vect(lonlat, atts = df, crs = crdref)
```

```{r, eval=FALSE}
# install.packages("ggplot2")
library(ggplot2)

# Scatter plot by group
ggplot(df, aes(x = altitude, y = precipitation, color = month)) +
    geom_point()
```
:::

# Readings

-   @lovelace_geocomputation_2025
-   @sds

# Session info

```{r}
sessionInfo()
```